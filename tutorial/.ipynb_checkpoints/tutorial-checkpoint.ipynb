{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beeHealth Tutorial\n",
    "### An introduction to Digital Health's library for localisation and activity metrics.\n",
    "##### Michał Kozłowski, Miquel Perelló Nieto, Ryan McConville"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The purpose of this tutorial is to introduce the functionality of this library and to provide a 'kick-start' for anyone aiming to use it, with the help of a few example scripts. We will initially concentrate on the two available examples, before moving onto ways in which this library can be expanded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for activity recognition\n",
    "\n",
    "In this section we will cover the use of 3-dimensional accelerometer signal as a basis for preprocessing, stratification, validation, classification and subsequent activity recognition metrics extraction. \n",
    "\n",
    "### Firstly, let's take care of the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bhealth.visualisations import plot_metrics\n",
    "from bhealth.visualisations import features_figure\n",
    "from bhealth.visualisations import plot_features\n",
    "from bhealth.visualisations import plot_test_train_splits\n",
    "from bhealth import data_loading_debug\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from bhealth.transforms import Transforms\n",
    "from bhealth.metrics import Metrics\n",
    "from bhealth.metric_wrappers import Wrapper\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function below calls the data loading script in the library. The data can be downloaded by following the instructions in the 'script' folder. The function outputs the raw data in the form of:\n",
    "\n",
    "- 'ts' - timestamp\n",
    "- 'xyz' - accelerometer data in 3-dimensions\n",
    "- 'labels' - corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_ts_X_y():\n",
    "\n",
    "    labels, ts, xyz = data_loading_debug.data_loader_accelerometer_debug()\n",
    "    return ts, xyz, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing performs various transformations on the actual dataset, so called 'feature extraction'. Here, the data undergoes the extraction of selected features. The full list of feature transforms can be found in the file 'transforms.py' and their tests under 'tests/test_transforms.py'.\n",
    "\n",
    "- The data is first windowed, and its overlap calculated (lines 5-11).\n",
    "- Instantiation of the Transforms object (line 13).\n",
    "- The appropriate feature transforms are selected and passed into the library as an array (lines 14-23).\n",
    "- The window is then iterated across the entirety of the data, and each of the transforms is calculated (lines 25-39).\n",
    "- Clean up operations follow (lines 41-49)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_X_y(ts, X, y):\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "\n",
    "    winlength_seconds = 10\n",
    "    overlap_seconds = 1\n",
    "    print(\"Window size of \"+str(winlength_seconds)+\" seconds and overlap of \"+str(float(overlap_seconds) / winlength_seconds)+\"%\")\n",
    "    samples_per_sec = 50\n",
    "    winlength = samples_per_sec * winlength_seconds\n",
    "    current = winlength\n",
    "    overlap = samples_per_sec * overlap_seconds\n",
    "\n",
    "    transform = Transforms(window_length=winlength, window_overlap=overlap)\n",
    "    print(\"Use number of mean crossings, spectral entropy as features...\")\n",
    "    feature_transforms = [transform.mean_crossings,\n",
    "                          transform.spec_entropy,\n",
    "                          transform.zero_crossings,\n",
    "                          transform.interq,\n",
    "                          transform.skewn,\n",
    "                          transform.spec_energy,\n",
    "                          transform.p25,\n",
    "                          transform.p75,\n",
    "                          transform.kurtosis]\n",
    "\n",
    "    while True:\n",
    "        windowed_raw = transform.slide(X)\n",
    "        if len(windowed_raw) > 0:\n",
    "            try:\n",
    "                windowed_features = [ts[transform.current_position][0]]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            for function in feature_transforms:\n",
    "                windowed_features.extend((np.apply_along_axis(function, 0, windowed_raw).tolist()))\n",
    "            new_X.append(windowed_features)\n",
    "\n",
    "            windowed_raw_labels = transform.slide(y, update=False)\n",
    "            most_freq_label = np.bincount(windowed_raw_labels).argmax()\n",
    "            new_y.append(most_freq_label)\n",
    "\n",
    "    # Convert lists to Numpy arrays\n",
    "    new_X = np.array(new_X)\n",
    "    # Remove datetime from features\n",
    "    new_X = new_X[:, 1:]\n",
    "    new_y = np.array(new_y)\n",
    "\n",
    "    new_X = transform.feature_selection(new_X, new_y, 'tree')\n",
    "\n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The split is the performed for fair cross validation of the algorithms. In this example, the data is split into two partitions for training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, y):\n",
    "    # Create train and test partitions\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "    train_index, test_index = skf.split(X, y).__next__()\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    plot_test_train_splits(y_train, y_test)\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier grid function selects the best set of parameters for a given classifier - in this case the classifier is a Random Forest. It will iteratively search through the provided parameters and output the set which gives best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_grid():\n",
    "    # Create cross-validation partitions from training\n",
    "    # This should select the best set of parameters\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "    clf = RandomForestClassifier()\n",
    "    param_grid = {'n_estimators' : [200, 250],\n",
    "                  'min_samples_leaf': [5, 10]}\n",
    "    clf_grid = GridSearchCV(clf, param_grid=param_grid, cv=cv, refit=True)\n",
    "    return clf_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following function simply prints out the summary of the parameters and the cross validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(clf_grid, X_test, y_test):\n",
    "    import numpy as np\n",
    "    print('Best parameters are: {}'.format(clf_grid.best_params_))\n",
    "    print(\"CV accuracy \"+str(np.mean(clf_grid.cv_results_['mean_test_score'])))\n",
    "\n",
    "    # The best model was fitted on the full training data, here it is tested only\n",
    "    tt_score = clf_grid.score(X_test, y_test)\n",
    "    print(\"Train / test split accuracy \"+str(tt_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics are calculated in the following function. Its usage underpins the entire library. The metrics can be chosen, according to the needs of the user much like the feature transform functions.\n",
    "\n",
    "- The current implementation can consider metrics across a variety of time spans - in this example we use daily and hourly metric calculation. This calls for the instantiation of the Wrapper class, where the user can specify what time spans should be used (lines 4-5).\n",
    "- Then, the labes and timestamps are cast into Pandas DataFrame object. This is for the internal use of the metric calculation (lines 7-9).\n",
    "- The metrics are then selected. This is done in a similar manner to the feature transforms above - through the use of array. The full list of implemented metrics can be found within the Wrapper class file 'metric_wrappers.py'. Note, that separate metrics for each of the time span duration can be chosen. \n",
    "- By running 'run_metric_array', the metrics are calculated and output in an array. This array outputs the metrics in the order in which they are provided by the user, i.e. in the example it would be 'duration_sitting', then 'number_of_unique_activities' and so  on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_metrics(labels, timestamps, span):\n",
    "    \"\"\"Outputs typical activity metrics.\"\"\"\n",
    "\n",
    "    descriptor_map = {\n",
    "                'sitting' : 77,\n",
    "                'walking' : 78,\n",
    "                'washing' : 79,\n",
    "                'eating'  : 80,\n",
    "                'sleeping': 81,\n",
    "                'studying': 82\n",
    "            }\n",
    "\n",
    "    metrics = Wrapper(labels, timestamps, span, 1, 25, descriptor_map, adjecency=None)\n",
    "\n",
    "    df_time = timestamps.astype('datetime64')\n",
    "    df_time = pd.DataFrame(df_time, columns=['Time'])\n",
    "    df_label = pd.DataFrame(labels, columns=['Label'])\n",
    "\n",
    "    metric_array= [metrics.duration_sitting,\n",
    "                   metrics.duration_walking,\n",
    "                   metrics.duration_washing,\n",
    "                   metrics.duration_eating,\n",
    "                   metrics.duration_sleeping,\n",
    "                   metrics.duration_studying,\n",
    "                   metrics.number_of_unique_activities]\n",
    "\n",
    "    metric_container, date_container = metrics.run_metric_array(metric_array)\n",
    "\n",
    "    return metric_container, date_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following structure in the 'main' function follows for all examples. The aim is to keep the entire pipeline the same:\n",
    "\n",
    "1. get_raw_ts_X_y loads the data.\n",
    "2. preprocess_X_y(ts, X, y) performs the preprocessing and feature extraction.\n",
    "3. split_train_test(X, y) splits the data into test and training.\n",
    "4. get_classifier_grid() performs the optimisation of the parameters.\n",
    "5. clf_grid.fit(X_train, y_train) fits the model to data.\n",
    "6. print_summary(clf_grid, X_test, y_test) validates the data and calculates the error.\n",
    "7. activity_metrics(y_test, ts) uses the evaluated labels to provide metrics of activity relating to health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 house folders.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-508972b9065c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_raw_ts_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfeatures_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/bHealth/bhealth/visualisations.py\u001b[0m in \u001b[0;36mfeatures_figure\u001b[0;34m(X, ts, feature_names, fig, ax, figsize)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautofmt_xdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     32\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     33\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ts, X, y = get_raw_ts_X_y()\n",
    "    features_figure(X[0:X.size:50], feature_names=['X', 'Y', 'Z'])\n",
    "\n",
    "    X, y = preprocess_X_y(ts, X, y)\n",
    "    (X_train, y_train), (X_test, y_test) = split_train_test(X, y)\n",
    "    clf_grid = get_classifier_grid()\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    print_summary(clf_grid, X_test, y_test)\n",
    "\n",
    "    metric_container_daily, date_container_daily = activity_metrics(y, ts, 'daily')\n",
    "    plot_metrics(metric_container_daily, date_container_daily)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for indoor localisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Localisation works very similarly to activity recognition, in that the entire structure is maintained. The only differences are the preprocessing steps, as well as the choice of classifiers and parameters. Once again, we load by get_raw_ts_X_y. This time however, since the indoor localisation performance is highly dependent upon the environment it is in (as opposed to activity, which it invariant to environment), we have a choice of 4 different houses.\n",
    "\n",
    "### Again, let's begin with dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from digihealth import data_loading_debug\n",
    "\n",
    "from digihealth.visualisations import plot_metrics\n",
    "from digihealth.visualisations import features_figure\n",
    "from digihealth.visualisations import features_figure_scatter\n",
    "from digihealth.visualisations import plot_test_train_splits\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from digihealth.metrics import Metrics\n",
    "from digihealth.transforms import Transforms\n",
    "from digihealth.metric_wrappers import Wrapper\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below function, get_raw_ts_X_y, works in the same way as the function above. It again loads the appropriate data. Note however, that the actual dimensionality of this data changes with each house (i.e. how many unique features there are in the dataset. This corresponds to the number of Access Points (APs) used in the indoor localisation experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_ts_X_y(house_):\n",
    "\n",
    "    ts, X, y = data_loading_debug.data_loader_rssi_debug(house_)\n",
    "    return ts, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from APs comes in the form of Received Signal Strength Indication (RSSI). This is measured in dBm. In our example, we retain the raw data from the receiver, and perform no feature extraction. This is just an assumption however, and the user is free to perform any preprocessing they see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_X_y(ts, X, y):\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split occurs in the same way as the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, y):\n",
    "    # Create train and test partitions\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "    y = y.astype(int)\n",
    "    train_index, test_index = skf.split(X, y).__next__()\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    plot_test_train_splits(y_train, y_test)\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the purposes of indoor localisation, we expand the space of parameters and classifiers used in this example. Note, that here we are comparing a variety of different classifiers, each with their own parameter space. They are:\n",
    "\n",
    "- Random Forest (rf)\n",
    "- Logistic Regression (lr)\n",
    "- Support Vector Classifier (svc)\n",
    "- Support Vector Classifier with Radial Basis Function kernel\n",
    "\n",
    "Ultimately, only rf is used to perform classification. This however can be easily changed, and new classifiers added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_grid():\n",
    "    # Create cross-validation partitions from training\n",
    "    # This should select the best set of parameters\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "    models = {'rf': {'model': RandomForestClassifier(),\n",
    "                     'parameters': {'n_estimators': [200, 250],\n",
    "                                    'min_samples_leaf': [1, 5, 10]}},\n",
    "              'lr': {'model': LogisticRegression(penalty='l2'),\n",
    "                     'parameters': {'C': [0.01, 0.1, 1, 10, 100]}},\n",
    "              'svc': {'model': SVC(probability=True),\n",
    "                      'parameters': [{'kernel': ['rbf'],\n",
    "                                      'gamma': [1e-3, 1e-4],\n",
    "                                      'C': [1, 10, 100, 1000]},\n",
    "                                     {'kernel': ['linear'],\n",
    "                                      'C': [1, 10, 100, 1000]}]},\n",
    "              'svc-rbf': {'model': SVC(probability=True),\n",
    "                          'parameters': [{'kernel': ['rbf'],\n",
    "                                          'gamma': [1e-3, 1e-4],\n",
    "                                          'C': [1, 10, 100, 1000]}, ]},\n",
    "              }\n",
    "\n",
    "    classifier_name = 'rf'\n",
    "\n",
    "    steps = [('imputer', SimpleImputer(missing_values=np.nan,\n",
    "                                       strategy='mean')),\n",
    "             ('scaler', StandardScaler()),\n",
    "             ('clf', models[classifier_name]['model'])]\n",
    "\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    pipeline_parameters = {'clf__' + key: value for key, value in\n",
    "                           models[classifier_name]['parameters'].items()}\n",
    "\n",
    "    clf_grid = GridSearchCV(pipeline, param_grid=pipeline_parameters, cv=cv,\n",
    "                            refit=True)\n",
    "    return clf_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function again prints out the summary of the classification, much like in the activity example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(clf_grid, X_test, y_test):\n",
    "    print('Best parameters are: {}'.format(clf_grid.best_params_))\n",
    "    print(\"CV accuracy \"+str(np.mean(clf_grid.cv_results_['mean_test_score'])))\n",
    "\n",
    "    # The best model was fitted on the full training data, here tested only\n",
    "    tt_score = clf_grid.score(X_test, y_test)\n",
    "    print(\"Train / test split accuracy \"+str(tt_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, that the metrics for localisation follow much and the same evaluation strategy. This is deliberate, as the objective here is to familiarise the user, and allow them to easily add their own modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localisation_metrics(labels, timestamps, span):\n",
    "    \"\"\"Outputs typical activity metrics.\"\"\"\n",
    "\n",
    "    descriptor_map = {\n",
    "        'foyer' : [0],\n",
    "        'bedroom' : [1],\n",
    "        'living_room' : [2],\n",
    "        'bathroom' : [3]\n",
    "    }\n",
    "\n",
    "    adjecency = [[0, 2.5, 3, 3.3],\n",
    "                 [2.5, 0, 6, 1.5],\n",
    "                 [3, 6, 0, 4],\n",
    "                 [3.3, 1.5, 4, 0]]\n",
    "\n",
    "    metrics = Wrapper(labels, timestamps, span, 1, 25, descriptor_map, adjecency)\n",
    "\n",
    "    df_time = timestamps.astype('datetime64')\n",
    "    df_time = pd.DataFrame(df_time, columns=['Time'])\n",
    "    df_label = pd.DataFrame(labels, columns=['Label'])\n",
    "\n",
    "    metric_array= [ metrics.walking_speed,\n",
    "                    metrics.room_transfers,\n",
    "                    metrics.number_of_unique_locations]\n",
    "\n",
    "    metric_container, date_container = metrics.run_metric_array(metric_array)\n",
    "\n",
    "    return metric_container, date_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following structure differs from the activity recognition 'main' function. This is because, we perform classification and metric extraction from 4 unique houses, which all differ in their localisation environment. In order to run this example 'per house' we iterate each house on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    houses = ['A']\n",
    "\n",
    "    for house_ in houses:\n",
    "\n",
    "        ts, X, y = get_raw_ts_X_y(house_)\n",
    "        features_figure(X, feature_names=['AP1', 'AP2', 'AP3', 'AP4', 'AP5', 'AP6', 'AP7', 'AP8'])\n",
    "\n",
    "        X, y = preprocess_X_y(ts, X, y)\n",
    "        (X_train, y_train), (X_test, y_test) = split_train_test(X, y)\n",
    "        clf_grid = get_classifier_grid()\n",
    "        clf_grid.fit(X_train, y_train)\n",
    "        print_summary(clf_grid, X_test, y_test)\n",
    "\n",
    "        metric_container_daily, date_container_daily = localisation_metrics(y, ts, 'daily')\n",
    "        plot_metrics(metric_container_daily, date_container_daily, labels_ = ['foyer', 'bedroom', 'living_room', 'bathroom'])\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
